---
title: "Practice 340 midterm"
output: html_document
---

### 1) Poisson.
**1a:** Compute the probability that a Poisson($\lambda = 1$) random variable is an even number. You can generate a poisson random variable with `rpois(n = 1,lambda = 1)`. You can check if `X` is even via 

```{r}
# the function %% finds remainder after dividing by a divisor
# then, ==0 checks if remainder is equal to 0. this is true if even
is.even = function(X) return((X%%2)==0)

is.even(112)
# also works on vector input
is.even(c(1,2,3,4,5))

mean(is.even(rpois(n = 1,lambda = 1)))
```
 
**1b:**  Compute the probability that a Poisson($\lambda = 10$) random variable is even.
```{r}
mean(is.even(rpois(n = 1000,lambda = 10)))
```

**1c:**  Compute the probability that a Poisson($\lambda = 10$) random variable is greater than 20.
```{r}
mean(rpois(n = 1000,lambda = 10)>20)
```

**1d:**  Let $X \sim$ Poisson($\lambda =10$).  Use Monte Carlo to compute $\mathbb{E}(X)$.
```{r}
# E(X) is the expectation
pois_vec = rpois(1e5,10)
mean(pois_vec)
```



### 2) Geometric
In class, we defined Geometric($p$) to be the number of failures required **before the first** success in a sequence of Bernoulli($p$) coin flips (remember this is also the definition used in `R` and `rgeom()`). So, FALSE FALSE TRUE would be 2. Some other places define Geometric($p$) to be the number of flips required **to get the first** success. So, FALSE FALSE TRUE would be 3. These definitions are very similar; the second is always one more than the first. However, this difference might get annoying if you aren't careful.

**2a:** Let $X \sim$ Geometric($p=1/10$) according to **the second definition** (i.e. always 1 more than the definition we use in class). Write a function to simulate $X$.
```{r}
rgeom(n=100, p=1/10) + 1
```

**2b:** Using the definitions in 2a, compute $\mathbb{E}(X)$ using Monte Carlo.
```{r}
mean(rgeom(n=100, p=1/10) + 1)
```

**2c:** Using the definitions in 2a, compute $P(X>20)$.
```{r}
twoc= rgeom(n=100, p=1/10)
mean(twoc>20)
```

**2d:** Both 2b and 1d ask to compute the expectation. How do the answers compare? Both 2c and 1d ask to compute the probability of being greater than 20. How do the answers compare? Make sense of this phenomenon by visualizing these two distributions (i.e. make their histograms); what's going on with the distributions?
```{r}
hist(pois_vec[0:100])
hist(twoc)
```


### 3) Meme proportions
Students posted 416 comments in Zoom chat during class. An expert panel has judged 47 of these comments to be memes. The big-bad-deans say that they are concerned "if there is evidence that more than 10% of comments are memes." So, this looks like bad news, 47/416 > 10%. Karl pleads with the deans: "Please, oh please, you big-bad-deans...memeing is totally random." (I don't actually know what this notion of "random" means, but please just run with it for this question.) Then, along comes you, saying that "because we have only observed 416 comments, we don't really know what the 'true proportion' of memes."

**3a:** What would be a good distribution for the number of memes?
```{r}
p_hat=47/416
mean(rbinom(1000,416,.1))
```

**3b:** Using your distribution from 3a, test the null hypothesis that the 'true proportion' is actually 10\%. It's all up to you now ... report the p-value.
```{r}
1-pbinom(46, 416, 0.1)
# null hypothesis is p=0.1
# 0.2 is bigger than .05
```

**3c:** After seeing your answer to 3b, the deans retort, "just because you failed to reject the null hypothesis does not mean that we accept your null hypothesis of 9%." But you respond, "you said you are concerned 'If there is evidence that more than 10% of comments are memes.'" We interpret our failure to reject as insufficient evidence that more than 10% of comments are memes. They begrudgingly go along with your point (and say that they are going to clarify their language in the future). In the end, they ask you to provide a 95% confidence interval for the true proportion. Provide a 95% confidence interval for the 'true proportion'.
```{r}
rb = rbinom(1000,416,p_hat)
quantile(rb/416, probs=c(0.025, 0.975), names=FALSE)
hist(rb/416)
```

